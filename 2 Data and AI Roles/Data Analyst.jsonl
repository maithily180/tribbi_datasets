{"question": "Mention three ways to make your model robust to outliers?", "answer": "Three ways to make a model robust to outliers are: 1) Use robust scaling, such as median and interquartile range, to normalize data, reducing the impact of extreme values. 2) Apply robust loss functions like Huber loss, which are less sensitive to outliers than mean squared error. 3) Use tree-based models like random forests, which are less affected by outliers due to their splitting mechanism.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Describe the motivation behind random forests and mention two reasons why they are better than individual decision trees?", "answer": "Random forests combine multiple decision trees to reduce overfitting and improve generalization by averaging predictions. Two reasons they are better: 1) They reduce variance through bagging, leading to stable outcomes. 2) Random feature selection prevents overfitting, unlike single trees that may overfit noisy data.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the differences and similarities between gradient boosting and random forest? and what are the advantages and disadvantages of each when compared to each other?", "answer": "Similarities: Both are tree-based ensemble methods, handle non-linear relationships, and require minimal preprocessing. Differences: Random forests use bagging with independent trees; gradient boosting trains trees sequentially to correct errors. Random forest advantages: 1) Faster due to parallelization. 2) Less prone to overfitting. Disadvantages: May miss complex patterns. Gradient boosting advantages: 1) Higher accuracy on complex data. 2) Captures sequential patterns. Disadvantages: 1) Slower training. 2) Sensitive to hyperparameters.", "difficulty": "hard", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are L1 and L2 regularization? What are the differences between the two?", "answer": "L1 (Lasso) regularization adds the absolute value of weights to the loss, promoting sparsity by setting some weights to zero. L2 (Ridge) adds the squared weights, shrinking them toward zero. Differences: 1) L1 creates sparse models for feature selection. 2) L2 handles multicollinearity better. 3) L1 is less sensitive to outliers than L2.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-off?", "answer": "Bias is error from overly simple models that underfit data. Variance is error from models overly sensitive to training data, causing overfitting. The bias-variance trade-off balances these to minimize total error. High-bias models (e.g., linear regression) miss patterns; high-variance models (e.g., deep trees) overfit. Optimal models balance complexity for low bias and variance.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Mention three ways to handle missing or corrupted data in a dataset?", "answer": "Three ways to handle missing data: 1) Imputation: Replace missing values with mean, median, or predictive methods like KNN. 2) Deletion: Remove rows/columns with excessive missing data if impact is minimal. 3) Use robust algorithms like tree-based models that handle missing values inherently.", "difficulty": "easy", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain briefly the logistic regression model and state an example of when you have used it recently?", "answer": "Logistic regression predicts binary outcomes by applying a sigmoid function to a linear combination of features, outputting probabilities. Example: Used to predict customer churn (churn=1, no churn=0) based on usage and subscription data, achieving 80% accuracy.", "difficulty": "easy", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. and what are the pros and cons for each of them?", "answer": "Batch Gradient Descent: Uses entire dataset for gradients, stable but slow. Pros: Converges to global minimum. Cons: High computational cost. Stochastic Gradient Descent: Uses one sample, fast but noisy. Pros: Quick for large data. Cons: May not converge optimally. Mini-batch Gradient Descent: Uses small batches, balancing speed and stability. Pros: Efficient, less noisy. Cons: Can get stuck in local minima.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain what is information gain and entropy in the context of decision trees?", "answer": "Entropy measures dataset impurity (0=pure, 1=mixed). Information gain is the reduction in entropy after a feature split, guiding decision tree splits. Higher information gain indicates better splits for class separation.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain the linear regression model and discuss its assumption?", "answer": "Linear regression predicts a continuous variable using a linear combination of features, minimizing error. Assumptions: 1) Linear relationship (check scatter plots). 2) Independent, constant-variance residuals (residual plots). 3) Normally distributed residuals (Q-Q plots). 4) Low multicollinearity (VIF<10). Violations may need transformations.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain briefly the K-Means clustering and how can we find the best value of K?", "answer": "K-Means partitions data into K clusters by minimizing within-cluster variance, iteratively updating centroids. To find optimal K, use the elbow method: plot within-cluster sum of squares (WCSS) vs. K, selecting K where WCSS reduction slows.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Define Precision, recall, and F1 and discuss the trade-off between them?", "answer": "Precision: True positives/(true + false positives), measures prediction accuracy. Recall: True positives/(true positives + false negatives), measures positive case coverage. F1: Harmonic mean of precision and recall. Trade-off: High precision reduces recall (fewer false positives, more missed positives), and vice versa. F1 balances both for imbalanced data.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the differences between a model that minimizes squared error and the one that minimizes the absolute error? and in which cases each error metric would be more appropriate?", "answer": "Mean Squared Error (MSE) weights large errors heavily, sensitive to outliers but easy to optimize. Mean Absolute Error (MAE) treats errors linearly, robust to outliers but harder to optimize. Use MSE for clean data or when large errors matter (e.g., finance). Use MAE for noisy data with outliers (e.g., sensor readings).", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Define and compare parametric and non-parametric models and give two examples for each of them?", "answer": "Parametric models assume a fixed form with few parameters, less flexible but data-efficient. Examples: Linear Regression, Logistic Regression. Non-parametric models adapt to data complexity, flexible but data-intensive. Examples: Decision Trees, Random Forests. Parametric models suit small, structured data; non-parametric models excel with large, complex data.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Explain the kernel trick in SVM and why we use it and how to choose what kernel to use?", "answer": "The kernel trick maps data to a higher-dimensional space for linear separation without explicit computation, using kernels (e.g., linear, RBF). It’s used for non-linear data. Choose linear kernel for linearly separable data, RBF for non-linear, using cross-validation to optimize.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Define the cross-validation process and the motivation behind using it?", "answer": "Cross-validation splits data into K folds, training on K-1 folds and testing on the remaining fold, repeating K times. Motivation: 1) Reduces overfitting by testing on unseen data. 2) Maximizes data use. 3) Provides robust performance metrics. It’s costly but vital for small datasets.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "You are building a binary classifier and you found that the data is imbalanced, what should you do to handle this situation?", "answer": "To handle imbalanced data: 1) Pre-processing: Use SMOTE for oversampling or downsample majority class. 2) In-processing: Apply class weights to penalize minority misclassification. 3) Post-processing: Use F1 score or ROC-AUC instead of accuracy for evaluation.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "You are working on a clustering problem, what are different evaluation metrics that can be used, and how to choose between them?", "answer": "Clustering metrics: 1) Silhouette Coefficient: Measures intra-cluster similarity vs. inter-cluster distance (-1 to 1, higher better). 2) Dunn’s Index: Ratio of minimum inter-cluster distance to maximum cluster size (higher better). Use Silhouette for general interpretability; Dunn’s for compact clusters. Consider data size and cluster shape.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is the ROC curve and when should you use it?", "answer": "The ROC curve plots True Positive Rate vs. False Positive Rate across thresholds, with AUC indicating model quality. Use for imbalanced datasets, model comparison, or when balancing TPR/FPR is critical (e.g., medical diagnostics).", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is the difference between hard and soft voting classifiers in the context of ensemble learners?", "answer": "Hard voting: Predicts the class with the most votes from individual classifiers. Soft voting: Averages predicted probabilities, choosing the highest. Soft voting is more accurate, leveraging confidence; hard voting is simpler but less nuanced.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is boosting in the context of ensemble learners discuss two famous boosting methods?", "answer": "Boosting combines weak learners sequentially, each correcting prior errors. Methods: 1) AdaBoost: Weights misclassified instances higher. 2) Gradient Boosting: Fits trees to residual errors, optimizing loss. Both boost accuracy but are noise-sensitive.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "How can you evaluate the performance of a dimensionality reduction algorithm on your dataset?", "answer": "Evaluate dimensionality reduction by: 1) Reconstruction error (lower is better) if reversible. 2) Downstream task performance (e.g., classifier accuracy) post-reduction; minimal drop indicates success. Use the second for non-reversible methods or preprocessing steps.", "difficulty": "hard", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Define the curse of dimensionality and how to solve it.", "answer": "The curse of dimensionality is data sparsity in high-dimensional spaces, increasing complexity and overfitting. Solutions: 1) Feature selection: Retain relevant features via correlation analysis. 2) Feature extraction: Apply PCA to reduce dimensions while preserving variance.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?", "answer": "Vanilla PCA: For small, in-memory datasets. Incremental PCA: For large datasets or online learning. Randomized PCA: For fast reduction on large datasets. Kernel PCA: For non-linear data needing complex transformations. Choose based on dataset size and linearity.", "difficulty": "hard", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Discuss two clustering algorithms that can scale to large datasets.", "answer": "1) Mini-batch K-Means: Clusters data in small batches, 3–4 times faster, ideal for large datasets. 2) BIRCH: Summarizes data compactly, clustering the summary, efficient for massive data. Both trade some accuracy for speed.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Do you need to scale your data if you will be using the SVM classifier and discuss your answer?", "answer": "Yes, SVMs require scaling because feature distances determine the decision boundary. Unscaled features with different ranges skew results toward dominant features. Standardization ensures equal contribution, improving model accuracy.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are Loss Functions and Cost Functions? Explain the key Difference Between them.", "answer": "Loss functions measure error for a single example (e.g., squared error). Cost functions average loss over a dataset or batch, guiding optimization. Difference: Loss is per instance; cost is aggregated. Cost functions drive training, while loss evaluates individual predictions.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is the importance of batch in machine learning and explain some batch depend on gradient descent algorithm?", "answer": "Batches enable efficient training by processing data subsets, reducing memory use. Types: 1) Batch Gradient Descent: Uses all data, stable but slow. 2) Stochastic Gradient Descent: Uses one sample, fast but noisy. 3) Mini-batch: Uses small batches, balancing speed and stability.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the different methods to split a tree in a decision tree algorithm?", "answer": "Classification splits: 1) Gini Index: Minimizes impurity. 2) Information Gain: Maximizes entropy reduction. Regression splits: Use Mean Squared Error, minimized greedily. Splits stop at max depth or minimum leaf size.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Why boosting is a more stable algorithm as compared to other ensemble algorithms?", "answer": "Boosting is stable because it trains learners sequentially, each correcting prior errors, reducing both bias and variance. Unlike bagging, which averages independent trees, boosting’s iterative correction focuses on hard cases, enhancing robustness.", "difficulty": "hard", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is active learning and discuss one strategy of it?", "answer": "Active learning involves models querying users to label informative data, improving efficiency. Strategy: Pool-based sampling selects the most uncertain samples from a pool for labeling, optimizing when labels are scarce.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the different approaches to implement recommendation systems?", "answer": "1) Content-based: Recommends similar items using features, good for cold starts. 2) Collaborative Filtering: Uses user behavior, accurate but struggles with cold starts. 3) Hybrid: Combines both for scalability and accuracy, common in industry.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the evaluation metrics that can be used for multi-label classification?", "answer": "Multi-label metrics: 1) Hamming Loss: Fraction of mispredicted labels. 2) Accuracy: Proportion of fully correct predictions. 3) Precision, Recall, F1: Per-label, with F1 balancing both. 4) Macro/Micro-F1: Handle imbalance. Use F1 for imbalanced data, accuracy for balanced.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What is the difference between concept and data drift and how to overcome each of them?", "answer": "Concept drift: Target-input relationship changes (e.g., evolving spam tactics). Mitigate with online learning or retraining. Data drift: Input feature distribution shifts (e.g., regional data changes). Monitor distributions and retrain or preprocess to adjust.", "difficulty": "hard", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "Can you explain the ARIMA model and its components?", "answer": "ARIMA forecasts time series with: 1) AR (p): Lagged observations. 2) I (d): Differencing for stationarity. 3) MA (q): Lagged error terms. Parameters p, d, q are tuned via AIC/BIC for linear, stationary data.", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}
{"question": "What are the assumptions made by the ARIMA model?", "answer": "ARIMA assumes: 1) Stationarity: Constant mean/variance, achieved via differencing. 2) Linearity: Linear data relationships. 3) No residual autocorrelation: Uncorrelated residuals (check via ACF plots). 4) Normally distributed residuals: Mean zero (validate with Q-Q plots).", "difficulty": "medium", "topic": "Machine Learning", "role": "Data Analyst"}